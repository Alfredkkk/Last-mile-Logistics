{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b99590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drl_comodal.py\n",
    "# Deep RL for joint ride-hailing & package delivery (no zoning)\n",
    "# Environment: diamond region (L1 metric), homogeneous Poisson arrivals, Poisson package field\n",
    "# Author: ChatGPT (PyTorch PPO)\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4e5151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1115835d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# Global knobs (easy tuning)\n",
    "# =========================\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# City / motion\n",
    "R = 20.0                 # half \"L1 radius\" of diamond region; feasible points satisfy |x|+|y| <= R\n",
    "V = 1.0                  # speed (distance units per minute)\n",
    "DT = 0.5                 # minutes per step\n",
    "HORIZON_MIN = 1440.0      # episode length in minutes (e.g., 4 hours)\n",
    "STEPS_PER_EP = int(HORIZON_MIN / DT)\n",
    "# terminal state: package 全部送完\n",
    "\n",
    "\n",
    "# Demand & revenue\n",
    "LAMBDA = 0.60            # ride arrival rate per minute (Poisson, spatially uniform over region)\n",
    "R_PICK_ALPHA = 0.5      # pickup visibility radius parameter r = alpha * R / sqrt(2) (L1-constraint approx)\n",
    "RT = 8.0                 # per-distance revenue for rides\n",
    "RP = 1.0                 # revenue per delivered package\n",
    "REWARD_SCALE = 1.0/8.0\n",
    "INV_REWARD_SCALE = 1.0/REWARD_SCALE\n",
    "REPORT_UNSCALED = True\n",
    "GAMMA_PACK = 0.8        # package spatial intensity (packages per unit area); area = R^2 for diamond in L1 model\n",
    "RIDE_TTL_MINUTES = 5    # ride request time to live in minutes\n",
    "\n",
    "# DRL obs/action shaping\n",
    "MAX_VISIBLE_RIDES = 5    # keep top-K closest pickups\n",
    "K_NEAREST_PACK = 10      # encode nearest K packages\n",
    "DISCOUNT = 0.99\n",
    "PPO_STEPS = 4096\n",
    "PPO_MINI_BATCH = 256\n",
    "PPO_EPOCHS = 4\n",
    "CLIP_EPS = 0.2\n",
    "VF_COEF = 0.5\n",
    "ENT_COEF = 0.02\n",
    "LR = 3e-4\n",
    "UPDATES = 200\n",
    "GAE_LAMBDA = 0.95\n",
    "\n",
    "# Heuristic\n",
    "SWITCH_GRACE_STEPS = 6\n",
    "#HEUR_ACCEPT_THRESHOLD = -0.25     # 基础放宽阈值（原本是 0）\n",
    "#HEUR_PICK_CAP        = 2.0        # 硬门：pickup 距离 <= 2.0 直接接\n",
    "#HEUR_W_PICK          = 1.0        # 分数里惩罚 pickup 距离的权重\n",
    "#HEUR_W_DROP          = 0.6        # 分数里“dropoff 近优于包裹”的权重（略高于原 0.5）\n",
    "#HEUR_W_TRIP          = 0.15       # 分数里对 trip_len 的微正则（鼓励有点路程的单）\n",
    "#HEUR_DYNAMIC_K       = 0.10       # 动态阈值强度（可调 0~0.2）\n",
    "HEUR_SOFT_PICK_CAP   = None        # 兜底门：pickup <= 3.0 时也可接（可关闭）\n",
    "\n",
    "\n",
    "\n",
    "EVAL_EPISODES = 5        # evaluation batch after each update\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14955366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============\n",
    "# Util functions\n",
    "# ==============\n",
    "def manhattan(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    return float(abs(a[0]-b[0]) + abs(a[1]-b[1]))\n",
    "\n",
    "def l1_inside(x: float, y: float, r: float) -> bool:\n",
    "    return abs(x) + abs(y) <= r\n",
    "\n",
    "def sample_uniform_point_in_diamond(R: float) -> np.ndarray:\n",
    "    # Rejection sampling in square [-R, R]^2 with L1 constraint\n",
    "    while True:\n",
    "        x = rng.uniform(-R, R)\n",
    "        y = rng.uniform(-R, R)\n",
    "        if abs(x) + abs(y) <= R:\n",
    "            return np.array([x, y], dtype=np.float32)\n",
    "\n",
    "# 正常情况来说，不会跑出去菱形范围，此处出于稳健性考虑，如在边界的时候因为数值误差导致跑出去了，则需要拉回来投影到最近的边界\n",
    "def project_to_diamond(p: np.ndarray, R: float) -> np.ndarray:\n",
    "    # If |x|+|y|>R, project to boundary along direction to origin\n",
    "    s = abs(p[0]) + abs(p[1])\n",
    "    if s <= R:\n",
    "        return p\n",
    "    if s == 0:\n",
    "        return np.array([0.0, 0.0], dtype=np.float32)\n",
    "    return p * (R / s)\n",
    "\n",
    "def step_towards(from_pt: np.ndarray, to_pt: np.ndarray, max_dist: float) -> Tuple[np.ndarray, float, bool]:\n",
    "    \"\"\"Move along Manhattan shortest path: first x, then y (or vice versa); return (new_pos, traveled, reached)\"\"\"\n",
    "    x0, y0 = from_pt\n",
    "    x1, y1 = to_pt\n",
    "    dx = abs(x1 - x0)\n",
    "    dy = abs(y1 - y0)\n",
    "    d = dx + dy\n",
    "    if d <= max_dist:\n",
    "        return to_pt.copy(), d, True\n",
    "    # Move along x first\n",
    "    move_x = min(dx, max_dist)\n",
    "    sign_x = np.sign(x1 - x0)\n",
    "    x_new = x0 + sign_x * move_x\n",
    "    remaining = max_dist - move_x\n",
    "    if remaining > 1e-8:\n",
    "        move_y = min(dy, remaining)\n",
    "        sign_y = np.sign(y1 - y0)\n",
    "        y_new = y0 + sign_y * move_y\n",
    "    else:\n",
    "        y_new = y0\n",
    "    p = np.array([x_new, y_new], dtype=np.float32)\n",
    "    return p, max_dist, False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c7d0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========================\n",
    "# Environment (no zoning)\n",
    "# ========================\n",
    "@dataclass\n",
    "class RideReq:\n",
    "    pickup: np.ndarray\n",
    "    dropoff: np.ndarray\n",
    "    trip_len: float\n",
    "\n",
    "class CoModalEnv:\n",
    "    \"\"\"\n",
    "    - Region: diamond |x|+|y| <= R (L1 metric)\n",
    "    - Packages: spatial Poisson with intensity gamma; N ~ Poisson(gamma * R^2), positions IID uniform in diamond\n",
    "    - Ride arrivals: Poisson(LAMBDA * DT) per step, each with (origin, destination) uniform in diamond\n",
    "    - Vehicle:\n",
    "        * cannot deliver packages while carrying passenger (pickup->dropoff)\n",
    "        * revenue: RP per delivered package; RT * (distance with passenger)\n",
    "    - Action (discrete): 0 = continue delivering package; i=1..MAX_VISIBLE_RIDES = accept ith visible ride (if available)\n",
    "      When busy enroute to pickup/dropoff, action is ignored (auto-continue).\n",
    "    - Observation: vector with normalized features:\n",
    "        * pos (x/R, y/R), time_frac, flags (to_pickup, with_pass)\n",
    "        * K nearest packages: for each, (dx/R, dy/R, l1/R)\n",
    "        * up to K rides visible: for each, (dx_pick/R, dy_pick/R, l1_pick/R, dx_drop/R, dy_drop/R, l1_trip/R)\n",
    "        * counts: remaining_pkg / (1 + E[N]), current_visible / MAX_VISIBLE_RIDES\n",
    "      Invalid slots are zero-padded. We also return an action mask for invalid ride indices.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 R: float = R,\n",
    "                 v: float = V,\n",
    "                 dt: float = DT,\n",
    "                 lam: float = LAMBDA,\n",
    "                 gamma_pack: float = GAMMA_PACK,\n",
    "                 rp: float = RP,\n",
    "                 rt: float = RT,\n",
    "                 r_pick_alpha: float = R_PICK_ALPHA,\n",
    "                 ride_ttl_minutes: float=RIDE_TTL_MINUTES): #ride request time to live in minutes\n",
    "        self.R = R\n",
    "        self.v = v\n",
    "        self.dt = dt\n",
    "        self.lam = lam\n",
    "        self.gamma = gamma_pack\n",
    "        self.rp = rp * REWARD_SCALE\n",
    "        self.rt = rt * REWARD_SCALE\n",
    "        # max pickup radius (L1) following r = alpha * R / sqrt(2); we keep L1 constraint\n",
    "        self.r_pick = r_pick_alpha * R / math.sqrt(2.0)\n",
    "\n",
    "        self.max_visible = MAX_VISIBLE_RIDES\n",
    "        self.k_pack = K_NEAREST_PACK\n",
    "        self.ride_ttl_steps = max(1, int(round(ride_ttl_minutes / self.dt)))\n",
    "        self._ended_reason: Optional[str] = None\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed: Optional[int] = None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        # sample packages\n",
    "        area = self.R ** 2  # for L1 diamond in the paper\n",
    "        n_pkg = rng.poisson(self.gamma * area)\n",
    "        n_pkg = max(1, int(n_pkg))  # ensure non-empty\n",
    "        self.packages = [sample_uniform_point_in_diamond(self.R) for _ in range(n_pkg)]\n",
    "        self.packages = np.array(self.packages, dtype=np.float32)\n",
    "\n",
    "        self.pos = np.array([0.0, 0.0], dtype=np.float32)\n",
    "        self.t = 0.0\n",
    "        self.ride_buffer: List[Tuple[RideReq, int]] = []\n",
    "        self.to_pickup: Optional[np.ndarray] = None\n",
    "        self.with_passenger: bool = False\n",
    "        self.drop_target: Optional[np.ndarray] = None\n",
    "\n",
    "        self.revenue_cum = 0.0\n",
    "        self._steps = 0\n",
    "        self._ended_reason = None\n",
    "        self.accepted_rides = 0\n",
    "        obs, mask = self._get_obs()\n",
    "        return obs, mask\n",
    "\n",
    "    def _append_new_ride(self, reqs: List[RideReq]):\n",
    "        \"\"\"Bring the new ride request to this buffer.\"\"\"\n",
    "        if not reqs:\n",
    "            return\n",
    "        ttl0 = self.ride_ttl_steps\n",
    "        self.ride_buffer.extend([(r, ttl0) for r in reqs])\n",
    "\n",
    "    def _sample_rides_this_step(self) -> List[RideReq]:\n",
    "        k = rng.poisson(self.lam * self.dt)\n",
    "        reqs = []\n",
    "        for _ in range(int(k)):\n",
    "            pk = sample_uniform_point_in_diamond(self.R)\n",
    "            dp = sample_uniform_point_in_diamond(self.R)\n",
    "            reqs.append(RideReq(pk, dp, manhattan(pk, dp)))\n",
    "        return reqs\n",
    "\n",
    "    def _visible_rides(self) -> List[RideReq]:\n",
    "        # only show rides with pickup within r_pick (L1) AND we can reach pickup before TTL expires\n",
    "        visible = []\n",
    "        for (r, ttl) in self.ride_buffer:\n",
    "            if ttl <= 0:\n",
    "                continue\n",
    "            # 1) 距离过滤：pickup 必须在可见半径内\n",
    "            if manhattan(self.pos, r.pickup) > self.r_pick:\n",
    "                continue\n",
    "            # 2) TTL + ETA 过滤：必须能在剩余 TTL 内赶到 pickup\n",
    "            eta_min = manhattan(self.pos, r.pickup) / self.v\n",
    "            if eta_min <= ttl * self.dt:        # <<< MOD-TTL-ETA: 核心检查\n",
    "                visible.append(r)\n",
    "        # 按 pickup 距离排序并截断\n",
    "        visible.sort(key=lambda rr: manhattan(self.pos, rr.pickup))\n",
    "        return visible[:self.max_visible]\n",
    "\n",
    "\n",
    "    def _nearest_package(self) -> Optional[np.ndarray]:\n",
    "        if len(self.packages) == 0:\n",
    "            return None\n",
    "        dists = np.abs(self.packages - self.pos).sum(axis=1)\n",
    "        idx = int(np.argmin(dists))\n",
    "        return self.packages[idx].copy()\n",
    "\n",
    "\n",
    "    def _deliver_if_arrived(self):\n",
    "        if len(self.packages) == 0:\n",
    "            return 0\n",
    "        # Deliver packages exactly at current location (robust with small threshold)\n",
    "        dists = np.abs(self.packages - self.pos).sum(axis=1)\n",
    "        hit = np.where(dists < 1e-6)[0]\n",
    "        delivered = len(hit)\n",
    "        if delivered > 0:\n",
    "            # deliver all that are exactly here (batch)\n",
    "            self.revenue_cum += self.rp * delivered\n",
    "            self.packages = np.delete(self.packages, hit, axis=0)\n",
    "        return delivered\n",
    "\n",
    "    def _get_obs(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        # Visible rides & nearest packages\n",
    "        visible = self._visible_rides()\n",
    "        # Packages features\n",
    "        pack_feats = []\n",
    "        if len(self.packages) > 0:\n",
    "            d = np.abs(self.packages - self.pos).sum(axis=1)\n",
    "            order = np.argsort(d)[:self.k_pack]\n",
    "            for j in order:\n",
    "                rel = (self.packages[j] - self.pos) / self.R\n",
    "                pack_feats.extend([rel[0], rel[1], d[j] / self.R])\n",
    "        # pad\n",
    "        while len(pack_feats) < 3 * self.k_pack:\n",
    "            pack_feats.append(0.0)\n",
    "\n",
    "        ride_feats = []\n",
    "        for r in visible:\n",
    "            relp = (r.pickup - self.pos) / self.R\n",
    "            reld = (r.dropoff - self.pos) / self.R\n",
    "            ride_feats.extend([relp[0], relp[1], manhattan(self.pos, r.pickup) / self.R,\n",
    "                               reld[0], reld[1], r.trip_len / self.R])\n",
    "        while len(ride_feats) < 6 * self.max_visible:\n",
    "            ride_feats.append(0.0)\n",
    "\n",
    "        time_frac = self.t / HORIZON_MIN\n",
    "        flags = [1.0 if self.to_pickup is not None else 0.0,\n",
    "                 1.0 if self.with_passenger else 0.0]\n",
    "\n",
    "        counts = [len(self.packages) / (1.0 + self.gamma * (self.R ** 2)),\n",
    "                  len(visible) / float(self.max_visible)]\n",
    "\n",
    "        core = [self.pos[0] / self.R, self.pos[1] / self.R, time_frac] + flags + counts\n",
    "        obs = np.array(core + pack_feats + ride_feats, dtype=np.float32)\n",
    "\n",
    "        # Action mask: 0 always valid; i>0 valid if i<=len(visible)\n",
    "        mask = np.zeros(1 + self.max_visible, dtype=np.float32)\n",
    "        mask[0] = 1.0\n",
    "        for i in range(len(visible)):\n",
    "            mask[1 + i] = 1.0\n",
    "        return obs, mask\n",
    "\n",
    "    def step(self, action: int):\n",
    "        reward = 0.0\n",
    "        done = False\n",
    "        delivered_step = 0 # track how many packages delivered in this step\n",
    "\n",
    "        # add fresh arrivals\n",
    "        self._append_new_ride(self._sample_rides_this_step())\n",
    "\n",
    "        # If busy towards pickup or with passenger, ignore action (auto-continue)\n",
    "        if self.to_pickup is not None:\n",
    "            # move towards pickup\n",
    "            new_pos, d, reached = step_towards(self.pos, self.to_pickup, self.v * self.dt)\n",
    "            self.pos = project_to_diamond(new_pos, self.R)\n",
    "            if reached:\n",
    "                self.to_pickup = None\n",
    "                self.with_passenger = True\n",
    "            # cannot deliver while enroute to pickup\n",
    "        elif self.with_passenger:\n",
    "            # move towards dropoff; accrue ride revenue per distance traveled\n",
    "            new_pos, d, reached = step_towards(self.pos, self.drop_target, self.v * self.dt)\n",
    "            self.pos = project_to_diamond(new_pos, self.R)\n",
    "            reward += self.rt * d    # ride distance revenue in this step\n",
    "            self.revenue_cum += self.rt * d\n",
    "            if reached:\n",
    "                self.with_passenger = False\n",
    "                self.drop_target = None\n",
    "        else:\n",
    "            # free: can choose to deliver or accept a visible ride\n",
    "            visible = self._visible_rides()\n",
    "            if action > 0 and action <= len(visible):\n",
    "                chosen = visible[action - 1]\n",
    "                # remove chosen from buffer\n",
    "                # (remove by identity)\n",
    "                for i, (r, ttl) in enumerate(self.ride_buffer):\n",
    "                    if r is chosen:\n",
    "                        self.ride_buffer.pop(i)\n",
    "                        break\n",
    "                # set pickup/drop targets\n",
    "                self.to_pickup = chosen.pickup.copy()\n",
    "                self.drop_target = chosen.dropoff.copy()\n",
    "                self.accepted_rides += 1\n",
    "                # move towards pickup immediately this step\n",
    "                new_pos, d, reached = step_towards(self.pos, self.to_pickup, self.v * self.dt)\n",
    "                self.pos = project_to_diamond(new_pos, self.R)\n",
    "                if reached:\n",
    "                    self.to_pickup = None\n",
    "                    self.with_passenger = True\n",
    "            else:\n",
    "                # deliver: go to nearest package (if any)\n",
    "                target = self._nearest_package()\n",
    "                if target is not None:\n",
    "                    new_pos, d, reached = step_towards(self.pos, target, self.v * self.dt)\n",
    "                    self.pos = project_to_diamond(new_pos, self.R)\n",
    "                    if reached:\n",
    "                        delivered = self._deliver_if_arrived()\n",
    "                        delivered_step += delivered\n",
    "                        reward += self.rp * delivered\n",
    "                # else idle at current location\n",
    "\n",
    "        # small clean-up: remove stale rides outside pickup radius (we keep buffer but they vanish after 1 step) and TTL Decay\n",
    "        # simple model: unaccepted rides expire by end of step\n",
    "        if self.ride_buffer:\n",
    "            new_buf = []\n",
    "            for (r, ttl) in self.ride_buffer:\n",
    "                ttl -= 1\n",
    "                if ttl > 0:\n",
    "                    new_buf.append((r, ttl))\n",
    "            self.ride_buffer = new_buf\n",
    "\n",
    "        self.t += self.dt\n",
    "        self._steps += 1\n",
    "\n",
    "        # Deliver any packages exactly at position (numerical safety)\n",
    "        if self.to_pickup is None and not self.with_passenger:\n",
    "            delivered = self._deliver_if_arrived()\n",
    "            if delivered > 0:\n",
    "                delivered_step += delivered\n",
    "                reward += self.rp * delivered\n",
    "        \n",
    "        # ---------- termination checks & terminal info ----------\n",
    "        done_horizon = (self.t >= HORIZON_MIN)\n",
    "        done_packages = (len(self.packages) == 0) and (not self.with_passenger) and (self.to_pickup is None)\n",
    "        \n",
    "        if done_packages or done_horizon:\n",
    "            done = True\n",
    "            self._ended_reason = \"packages_done\" if done_packages else \"horizon_reached\"\n",
    "        \n",
    "        info: Dict[str, object] = {}\n",
    "        if done:\n",
    "            info[\"terminal_time_min\"] = float(self.t)\n",
    "            info[\"ended_reason\"] = self._ended_reason\n",
    "            info[\"accepted_rides\"] = int(self.accepted_rides)\n",
    "\n",
    "        info[\"delivered_step\"] = int(delivered_step)\n",
    "        \n",
    "        obs, mask = self._get_obs()\n",
    "        return obs, reward, done, info, mask\n",
    "\n",
    "    @property\n",
    "    def obs_dim(self):\n",
    "        # core (3 + 2 flags + 2 counts) + 3*K + 6*MAX_VISIBLE\n",
    "        return (3 + 2 + 2) + 3 * self.k_pack + 6 * self.max_visible\n",
    "\n",
    "    @property\n",
    "    def act_dim(self):\n",
    "        return 1 + self.max_visible\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1f5263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =================\n",
    "# Baseline policies\n",
    "# =================\n",
    "def run_episode(env: CoModalEnv, policy=None, greedy=False) -> Tuple[float, float, float, str, int]:\n",
    "    obs, mask = env.reset()\n",
    "    total = 0.0\n",
    "    terminal_time = None\n",
    "    ended_reason = \"unknown\"\n",
    "    acc = 0\n",
    "    for _ in range(STEPS_PER_EP):\n",
    "        if policy is None:\n",
    "            # default: deliver-only baseline\n",
    "            action = 0\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                o = torch.tensor(obs, dtype=torch.float32, device=DEVICE).unsqueeze(0)\n",
    "                m = torch.tensor(mask, dtype=torch.float32, device=DEVICE).unsqueeze(0)\n",
    "                logits, _ = policy(o)\n",
    "                # mask invalid\n",
    "                invalid = (m < 0.5)\n",
    "                logits = logits.masked_fill(invalid, -1e9)\n",
    "                if greedy:\n",
    "                    action = int(torch.argmax(logits, dim=-1).item())\n",
    "                else:\n",
    "                    probs = torch.softmax(logits, dim=-1)\n",
    "                    action = int(torch.multinomial(probs, 1).item())\n",
    "        obs, r, done, info, mask = env.step(action)\n",
    "        total += r\n",
    "        if done:\n",
    "            terminal_time = float(info.get(\"terminal_time_min\", env.t))\n",
    "            ended_reason = str(info.get(\"ended_reason\", env._ended_reason or \"unknown\"))\n",
    "            acc = int(info.get(\"accepted_rides\", getattr(env, \"accepted_rides\", 0)))\n",
    "            break\n",
    "    if terminal_time is None:\n",
    "        terminal_time = float(env.t)\n",
    "    revenue_rate = total / terminal_time if terminal_time > 0 else 0.0\n",
    "    \n",
    "    return total, terminal_time, revenue_rate, ended_reason, acc\n",
    "\n",
    "\"\"\"\n",
    "def baseline_nearby_rule(env: CoModalEnv, pickup_alpha=R_PICK_ALPHA, drop_bias=0.5) -> Tuple[float, float, float, str, int]:\n",
    "    \n",
    "#    Heuristic 放宽版：\n",
    "#      1) 硬门：若存在 pickup 距离 <= HEUR_PICK_CAP 的单，直接接最近。\n",
    "#      2) 打分：score = -w_pick*pk_d + w_drop*(nn_d - dp_d) + w_trip*trip_len\n",
    "#         满足 score > threshold 则接；threshold 可随 nn_d 动态放宽。\n",
    "#      3) 兜底：若仍不接、且 min pk_d <= HEUR_SOFT_PICK_CAP，则接最近。\n",
    "#    返回: total_reward, terminal_time, revenue_rate, ended_reason, accepted_rides\n",
    "    \n",
    "    obs, mask = env.reset()\n",
    "    total = 0.0\n",
    "    terminal_time = None\n",
    "    ended_reason = \"unknown\"\n",
    "    acc = 0\n",
    "\n",
    "    for _ in range(STEPS_PER_EP):\n",
    "        visible = env._visible_rides()\n",
    "        action = 0\n",
    "\n",
    "        if len(visible) > 0:\n",
    "            # 1) 硬门：超近 pickup 直接接\n",
    "            pk_d_list = [manhattan(env.pos, r.pickup) for r in visible]\n",
    "            min_pk_d = min(pk_d_list)\n",
    "            if min_pk_d <= HEUR_PICK_CAP:\n",
    "                action = 1 + int(np.argmin(pk_d_list))\n",
    "            else:\n",
    "                # 2) 打分：结合 pickup 惩罚、drop 相对包裹优势、适度 trip_len 激励\n",
    "                nn = env._nearest_package()\n",
    "                nn_d = manhattan(env.pos, nn) if nn is not None else 0.0\n",
    "\n",
    "                best_score, chosen_idx = -1e9, -1\n",
    "                for i, r in enumerate(visible):\n",
    "                    pk_d = pk_d_list[i]\n",
    "                    dp_d = manhattan(env.pos, r.dropoff)\n",
    "                    s = (-HEUR_W_PICK * pk_d\n",
    "                         + HEUR_W_DROP * (nn_d - dp_d)\n",
    "                         + HEUR_W_TRIP * r.trip_len)\n",
    "                    if s > best_score:\n",
    "                        best_score, chosen_idx = s, i\n",
    "\n",
    "                # 动态阈值：包裹越远（nn_d 大），越容易放宽\n",
    "                dyn = HEUR_ACCEPT_THRESHOLD - HEUR_DYNAMIC_K * (nn_d / max(1.0, env.R))\n",
    "                if best_score > dyn:\n",
    "                    action = 1 + chosen_idx\n",
    "                else:\n",
    "                    # 3) 兜底：仍未满足阈值，但 pickup 不算远，就接最近\n",
    "                    if HEUR_SOFT_PICK_CAP and (min_pk_d <= HEUR_SOFT_PICK_CAP):\n",
    "                        action = 1 + int(np.argmin(pk_d_list))\n",
    "\n",
    "        obs, r, done, info, mask = env.step(action)\n",
    "        total += r\n",
    "        if done:\n",
    "            terminal_time = float(info.get(\"terminal_time_min\", env.t))\n",
    "            ended_reason  = str(info.get(\"ended_reason\", env._ended_reason or \"unknown\"))\n",
    "            acc = int(info.get(\"accepted_rides\", getattr(env, \"accepted_rides\", 0)))\n",
    "            break\n",
    "\n",
    "    if terminal_time is None:\n",
    "        terminal_time = float(env.t)\n",
    "    revenue_rate = (total / terminal_time) if terminal_time > 0 else 0.0\n",
    "    return total, terminal_time, revenue_rate, ended_reason, acc\n",
    "    \"\"\"\n",
    "def baseline_nearby_rule(env: CoModalEnv, pickup_alpha=R_PICK_ALPHA, drop_bias=0.5) -> Tuple[float, float, float, str, int]:\n",
    "    \"\"\"\n",
    "    Switching policy (N = n) 实现：\n",
    "      - 只有在“刚送完一个包裹”的下一次决策时刻检查一次乘客：\n",
    "          若存在可见乘客（pickup 在 r_pick 内且 TTL>0），就接“pickup 最近”的一单；\n",
    "          若没有，就继续去最近包裹。\n",
    "      - 完成该乘客行程后，立即回到送最近包裹。\n",
    "      - 其他时刻（并非刚送完包裹），一律优先送最近包裹（action = 0）。\n",
    "    返回: (total_reward, terminal_time_min, revenue_rate, ended_reason, accepted_rides)\n",
    "    \"\"\"\n",
    "    obs, mask = env.reset()\n",
    "    total = 0.0\n",
    "    terminal_time = None\n",
    "    ended_reason = \"unknown\"\n",
    "    acc = 0\n",
    "\n",
    "    grace_left = int(SWITCH_GRACE_STEPS) if False else 0\n",
    "\n",
    "    for _ in range(STEPS_PER_EP):\n",
    "        visible = env._visible_rides()\n",
    "        action = 0  # 默认：去最近包裹\n",
    "        \n",
    "        #Pre-grace\n",
    "        # 若下一步就能把最近包裹送达，则提前开启窗口\n",
    "        nn = env._nearest_package()\n",
    "        if nn is not None:\n",
    "            dist_to_nn = manhattan(env.pos, nn)\n",
    "            if grace_left == 0 and dist_to_nn <= (env.v * env.dt):\n",
    "                grace_left = max(1, int(SWITCH_GRACE_STEPS))\n",
    "                \n",
    "\n",
    "        if grace_left > 0:\n",
    "            # 窗口内：只要有合格单，就接 pickup 最近的一单\n",
    "            if len(visible) > 0:\n",
    "                # 接 pickup 最近的一单\n",
    "                pk_d_list = [manhattan(env.pos, r.pickup) for r in visible]\n",
    "                if HEUR_SOFT_PICK_CAP and min(pk_d_list) <= HEUR_SOFT_PICK_CAP:\n",
    "                    action = 1 + int(np.argmin(pk_d_list))\n",
    "                    grace_left = 0\n",
    "                    \n",
    "                else:\n",
    "                    action = 1 + int(np.argmin(pk_d_list))\n",
    "                    grace_left = 0\n",
    "            else:\n",
    "                # 窗口内没有合格单，则窗口计数器减1\n",
    "                grace_left -= 1\n",
    "\n",
    "        # 执行动作\n",
    "        obs, r, done, info, mask = env.step(action)\n",
    "        total += r\n",
    "\n",
    "        delivered_cnt = int(info.get(\"delivered_this_step\", 0))\n",
    "        if delivered_cnt > 0:\n",
    "            # 送完包裹：开启新窗口（含当前后续的 SWITCH_GRACE_STEPS 步）\n",
    "            grace_left = max(1,int(SWITCH_GRACE_STEPS))\n",
    "\n",
    "\n",
    "        if done:\n",
    "            terminal_time = float(info.get(\"terminal_time_min\", env.t))\n",
    "            ended_reason  = str(info.get(\"ended_reason\", env._ended_reason or \"unknown\"))\n",
    "            acc = int(info.get(\"accepted_rides\", getattr(env, \"accepted_rides\", 0)))\n",
    "            break\n",
    "\n",
    "    if terminal_time is None:\n",
    "        terminal_time = float(env.t)\n",
    "    revenue_rate = (total / terminal_time) if terminal_time > 0 else 0.0\n",
    "    return total, terminal_time, revenue_rate, ended_reason, acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "239ef0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============\n",
    "# PPO Components\n",
    "# ==============\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, obs_dim: int, act_dim: int):\n",
    "        super().__init__()\n",
    "        hid = 256\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_dim, hid), \n",
    "            nn.LayerNorm(hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hid, hid), \n",
    "            nn.LayerNorm(hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "        self.pi = nn.Linear(hid, act_dim)\n",
    "        self.v  = nn.Linear(hid, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        h = self.net(x)\n",
    "        return self.pi(h), self.v(h)\n",
    "\n",
    "\n",
    "def ppo_update(policy: ActorCritic, optimizer, batch, clip_eps=CLIP_EPS):\n",
    "    obs, act, old_logp, ret, adv, mask = batch\n",
    "    logits, v = policy(obs)\n",
    "    # mask invalid actions\n",
    "    invalid = (mask < 0.5)\n",
    "    logits = logits.masked_fill(invalid, -1e9)\n",
    "    dist = torch.distributions.Categorical(logits=logits)\n",
    "    logp = dist.log_prob(act)\n",
    "    ratio = torch.exp(logp - old_logp)\n",
    "\n",
    "    clip_adv = torch.clamp(ratio, 1.0 - clip_eps, 1.0 + clip_eps) * adv\n",
    "    pi_loss = -(torch.min(ratio * adv, clip_adv)).mean()\n",
    "    v_loss = ((ret - v.squeeze(-1)) ** 2).mean()\n",
    "\n",
    "    ent = dist.entropy().mean()\n",
    "    loss = pi_loss + VF_COEF * v_loss - ENT_COEF * ent\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(policy.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    return pi_loss.item(), v_loss.item(), ent.item(), loss.item()\n",
    "\n",
    "\n",
    "def collect_rollout(env: CoModalEnv, policy: ActorCritic, steps: int):\n",
    "    # buffers\n",
    "    obs_buf, act_buf, rew_buf, val_buf, next_val_buf, logp_buf, mask_buf, done_buf = [], [], [], [], [], [], [], []\n",
    "\n",
    "    obs, mask = env.reset()\n",
    "    for _ in range(steps):\n",
    "        o = torch.tensor(obs, dtype=torch.float32, device=DEVICE).unsqueeze(0)\n",
    "        m = torch.tensor(mask, dtype=torch.float32, device=DEVICE).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            logits, v = policy(o)\n",
    "            invalid = (m < 0.5)\n",
    "            logits = logits.masked_fill(invalid, -1e9)\n",
    "            dist = torch.distributions.Categorical(logits=logits)\n",
    "            a = dist.sample()\n",
    "            logp = dist.log_prob(a).squeeze(0)\n",
    "            v_cur = v.squeeze(0).squeeze(-1)             # V(s_t)\n",
    "\n",
    "        # step env\n",
    "        obs2, r, done, _, mask2 = env.step(int(a.item()))\n",
    "\n",
    "        # compute V(s_{t+1}) for GAE bootstrap\n",
    "        with torch.no_grad():\n",
    "            o2 = torch.tensor(obs2, dtype=torch.float32, device=DEVICE).unsqueeze(0)\n",
    "            _, v_next = policy(o2)\n",
    "            v_next = v_next.squeeze(0).squeeze(-1)       # V(s_{t+1})\n",
    "\n",
    "        # store\n",
    "        obs_buf.append(o.squeeze(0).cpu().numpy())\n",
    "        mask_buf.append(m.squeeze(0).cpu().numpy())\n",
    "        act_buf.append(a.cpu().numpy())\n",
    "        rew_buf.append(r)\n",
    "        val_buf.append(v_cur.cpu().numpy())\n",
    "        next_val_buf.append(v_next.cpu().numpy())\n",
    "        logp_buf.append(logp.cpu().numpy())\n",
    "        done_buf.append(done)\n",
    "\n",
    "        obs, mask = obs2, mask2\n",
    "        if done:\n",
    "            obs, mask = env.reset()\n",
    "\n",
    "    # ---------- GAE(λ) advantages & returns ----------\n",
    "    # arrays\n",
    "    rewards = np.array(rew_buf, dtype=np.float32)\n",
    "    values  = np.array(val_buf, dtype=np.float32)\n",
    "    next_values = np.array(next_val_buf, dtype=np.float32)\n",
    "    dones   = np.array(done_buf, dtype=np.float32)  # 1.0 if done else 0.0\n",
    "\n",
    "    advantages = np.zeros_like(rewards, dtype=np.float32)\n",
    "    gae = 0.0\n",
    "    gamma = DISCOUNT\n",
    "    lam = GAE_LAMBDA\n",
    "\n",
    "    # backward recursion\n",
    "    for t in reversed(range(len(rewards))):\n",
    "        nonterminal = 1.0 - dones[t]\n",
    "        delta = rewards[t] + gamma * next_values[t] * nonterminal - values[t]\n",
    "        gae = delta + gamma * lam * nonterminal * gae\n",
    "        advantages[t] = gae\n",
    "\n",
    "    returns = advantages + values  # target for value head\n",
    "\n",
    "    # tensors\n",
    "    obs_t  = torch.tensor(np.array(obs_buf), dtype=torch.float32, device=DEVICE)\n",
    "    act_t  = torch.tensor(np.array(act_buf).squeeze(-1), dtype=torch.long, device=DEVICE)\n",
    "    ret_t  = torch.tensor(returns, dtype=torch.float32, device=DEVICE)\n",
    "    adv_t  = torch.tensor(advantages, dtype=torch.float32, device=DEVICE)\n",
    "    logp_t = torch.tensor(np.array(logp_buf), dtype=torch.float32, device=DEVICE)\n",
    "    mask_t = torch.tensor(np.array(mask_buf), dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "    # normalize advantages (keep returns unnormalized)\n",
    "    adv_t = (adv_t - adv_t.mean()) / (adv_t.std() + 1e-8)\n",
    "\n",
    "    return obs_t, act_t, logp_t, ret_t, adv_t, mask_t\n",
    "\n",
    "\n",
    "\n",
    "def make_minibatches(batch, batch_size):\n",
    "    N = batch[0].shape[0]\n",
    "    idx = np.arange(N)\n",
    "    rng.shuffle(idx)\n",
    "    for i in range(0, N, batch_size):\n",
    "        j = idx[i:i+batch_size]\n",
    "        yield tuple(x[j] for x in batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06a6a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all(env: CoModalEnv, policy: ActorCritic):\n",
    "    prev_mode = policy.training\n",
    "    policy.eval()\n",
    "    try:\n",
    "        # 采集的元组仍然是缩放后的（训练口径）\n",
    "        drl_eps  = [run_episode(env, policy, greedy=True) for _ in range(EVAL_EPISODES)]\n",
    "        pure_eps = [run_episode(env, policy=None)        for _ in range(EVAL_EPISODES)]\n",
    "        heur_eps = [baseline_nearby_rule(env)            for _ in range(EVAL_EPISODES)]\n",
    "\n",
    "        # <<< MOD-REPORT: 小工具，把 R/Rate 反缩放；T/ended_reason/accepted 不动\n",
    "        def _descale_eps(eps):\n",
    "            if not REPORT_UNSCALED:\n",
    "                return eps\n",
    "            fixed = []\n",
    "            for e in eps:\n",
    "                # e 可能是 4 元组或 5 元组，取决于你是否已合入“接单数”\n",
    "                if len(e) == 5:\n",
    "                    R, T, Rate, reason, acc = e\n",
    "                    fixed.append((R * INV_REWARD_SCALE, T, Rate * INV_REWARD_SCALE, reason, acc))\n",
    "                else:  # 兼容旧版（4 元组）\n",
    "                    R, T, Rate, reason = e\n",
    "                    fixed.append((R * INV_REWARD_SCALE, T, Rate * INV_REWARD_SCALE, reason))\n",
    "            return fixed\n",
    "\n",
    "        drl_out  = _descale_eps(drl_eps)\n",
    "        pure_out = _descale_eps(pure_eps)\n",
    "        heur_out = _descale_eps(heur_eps)\n",
    "\n",
    "        # 聚合在（可能）反缩放后的数据上做，这样打印均值就是原单位\n",
    "        def agg(eps):\n",
    "            R  = np.array([e[0] for e in eps], dtype=float)\n",
    "            T  = np.array([e[1] for e in eps], dtype=float)\n",
    "            Rt = np.array([e[2] for e in eps], dtype=float)\n",
    "            out = dict(avg_reward=R.mean(), avg_t=T.mean(), avg_rate=Rt.mean())\n",
    "            if len(eps[0]) == 5:\n",
    "                A  = np.array([e[4] for e in eps], dtype=float)\n",
    "                out[\"avg_acc\"] = A.mean()\n",
    "            return out\n",
    "\n",
    "        # 打印逐集明细（展示层口径）\n",
    "        def pprint(name, eps):\n",
    "            print(f\"  {name} episodes:\")\n",
    "            if len(eps[0]) == 5:\n",
    "                for i, (R, T, rate, reason, acc) in enumerate(eps):\n",
    "                    mark = \" (early-packages-done)\" if reason == \"packages_done\" else \"\"\n",
    "                    print(f\"    Ep{i+1:02d}: reward={R:8.2f}, terminal_time={T:7.2f} min, rate={rate:6.3f}/min, accepted={acc:3d}, reason={reason}{mark}\")\n",
    "            else:\n",
    "                for i, (R, T, rate, reason) in enumerate(eps):\n",
    "                    mark = \" (early-packages-done)\" if reason == \"packages_done\" else \"\"\n",
    "                    print(f\"    Ep{i+1:02d}: reward={R:8.2f}, terminal_time={T:7.2f} min, rate={rate:6.3f}/min, reason={reason}{mark}\")\n",
    "\n",
    "        pprint(\"DRL \", drl_out)\n",
    "        pprint(\"HEUR\", heur_out)\n",
    "        pprint(\"PURE\", pure_out)\n",
    "\n",
    "        return {\"drl\": agg(drl_out), \"heur\": agg(heur_out), \"pure\": agg(pure_out)}\n",
    "    finally:\n",
    "        if prev_mode:\n",
    "            policy.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "989356cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    env = CoModalEnv()\n",
    "    policy = ActorCritic(env.obs_dim, env.act_dim).to(DEVICE)\n",
    "    policy.train()\n",
    "    optimizer = optim.Adam(policy.parameters(), lr=LR)\n",
    "\n",
    "    print(f\"Device: {DEVICE}, obs_dim={env.obs_dim}, act_dim={env.act_dim}\")\n",
    "    print(\"Start training PPO...\")\n",
    "    for upd in range(1, UPDATES + 1):\n",
    "        batch = collect_rollout(env, policy, PPO_STEPS)\n",
    "        for _ in range(PPO_EPOCHS):\n",
    "            for mb in make_minibatches(batch, PPO_MINI_BATCH):\n",
    "                pi_l, v_l, ent, tot = ppo_update(policy, optimizer, mb, CLIP_EPS)\n",
    "        if upd % 5 == 0:\n",
    "            metrics = evaluate_all(env, policy)\n",
    "            drl, heur, pure = metrics[\"drl\"], metrics[\"heur\"], metrics[\"pure\"]\n",
    "            print(f\"[Upd {upd:03d}] \"\n",
    "            f\"DRL:  R={drl['avg_reward']:8.2f}, T={drl['avg_t']:7.2f}m, Rate={drl['avg_rate']:6.3f}/m, Acc={drl['avg_acc']:5.2f} | \"  # <<< MOD-ACCEPT\n",
    "            f\"HEUR: R={heur['avg_reward']:8.2f}, T={heur['avg_t']:7.2f}m, Rate={heur['avg_rate']:6.3f}/m | \"\n",
    "            f\"PURE: R={pure['avg_reward']:8.2f}, T={pure['avg_t']:7.2f}m, Rate={pure['avg_rate']:6.3f}/m \"\n",
    "            f\"|| pi={pi_l:.3f} v={v_l:.3f} ent={ent:.3f}\")\n",
    "\n",
    "    # Final evaluation\n",
    "    metrics = evaluate_all(env, policy)\n",
    "    drl, heur, pure = metrics[\"drl\"], metrics[\"heur\"], metrics[\"pure\"]\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Final evaluation over {EVAL_EPISODES} eps (<= {HORIZON_MIN:.0f} min each):\")\n",
    "    print(f\"  DRL (greedy):        R={drl['avg_reward']:.2f}, T={drl['avg_t']:.2f}m, Rate={drl['avg_rate']:.3f}/m, Acc={drl['avg_acc']:.2f}\")  \n",
    "    print(f\"  Nearby heuristic:    R={heur['avg_reward']:.2f}, T={heur['avg_t']:.2f}m, Rate={heur['avg_rate']:.3f}/m\")\n",
    "    print(f\"  Pure delivery only:  R={pure['avg_reward']:.2f}, T={pure['avg_t']:.2f}m, Rate={pure['avg_rate']:.3f}/m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eccb0f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu, obs_dim=67, act_dim=6\n",
      "Start training PPO...\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3599.00, terminal_time=1201.50 min, rate= 2.995/min, accepted= 23, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3307.44, terminal_time=1129.50 min, rate= 2.928/min, accepted= 23, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2123.32, terminal_time= 985.50 min, rate= 2.155/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 4025.26, terminal_time=1291.50 min, rate= 3.117/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 4175.86, terminal_time=1341.00 min, rate= 3.114/min, accepted= 25, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2619.50, terminal_time=1074.50 min, rate= 2.438/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2888.42, terminal_time=1077.50 min, rate= 2.681/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2250.21, terminal_time= 954.00 min, rate= 2.359/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 1964.27, terminal_time= 976.50 min, rate= 2.012/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 1796.00, terminal_time= 949.00 min, rate= 1.893/min, accepted= 10, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  308.00, terminal_time= 654.00 min, rate= 0.471/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  294.00, terminal_time= 648.00 min, rate= 0.454/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  347.00, terminal_time= 681.00 min, rate= 0.510/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  337.00, terminal_time= 715.50 min, rate= 0.471/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  334.00, terminal_time= 671.00 min, rate= 0.498/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 005] DRL:  R= 3446.18, T=1189.80m, Rate= 2.862/m, Acc=21.00 | HEUR: R= 2303.68, T=1006.30m, Rate= 2.276/m | PURE: R=  324.00, T= 673.90m, Rate= 0.481/m || pi=0.065 v=14.742 ent=0.018\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 1855.60, terminal_time= 924.00 min, rate= 2.008/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 4325.32, terminal_time=1295.50 min, rate= 3.339/min, accepted= 30, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 4851.15, terminal_time=1440.00 min, rate= 3.369/min, accepted= 35, reason=horizon_reached\n",
      "    Ep04: reward= 1263.67, terminal_time= 850.50 min, rate= 1.486/min, accepted=  7, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3087.01, terminal_time=1031.50 min, rate= 2.993/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 3739.09, terminal_time=1248.00 min, rate= 2.996/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2972.24, terminal_time=1169.00 min, rate= 2.543/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2725.35, terminal_time=1076.50 min, rate= 2.532/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3631.31, terminal_time=1263.50 min, rate= 2.874/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 1844.16, terminal_time= 985.50 min, rate= 1.871/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  352.00, terminal_time= 690.00 min, rate= 0.510/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  314.00, terminal_time= 641.50 min, rate= 0.489/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  333.00, terminal_time= 692.50 min, rate= 0.481/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  330.00, terminal_time= 630.00 min, rate= 0.524/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  337.00, terminal_time= 651.50 min, rate= 0.517/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 010] DRL:  R= 3076.55, T=1108.30m, Rate= 2.639/m, Acc=20.80 | HEUR: R= 2982.43, T=1148.50m, Rate= 2.563/m | PURE: R=  333.20, T= 661.10m, Rate= 0.504/m || pi=-0.050 v=16.779 ent=0.006\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3945.48, terminal_time=1252.50 min, rate= 3.150/min, accepted= 25, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3629.85, terminal_time=1225.50 min, rate= 2.962/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2255.59, terminal_time= 974.50 min, rate= 2.315/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3455.62, terminal_time=1172.50 min, rate= 2.947/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3652.84, terminal_time=1179.50 min, rate= 3.097/min, accepted= 23, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2014.44, terminal_time= 933.50 min, rate= 2.158/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3130.08, terminal_time=1174.00 min, rate= 2.666/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2692.23, terminal_time=1070.50 min, rate= 2.515/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2920.58, terminal_time=1067.00 min, rate= 2.737/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 1553.78, terminal_time= 826.00 min, rate= 1.881/min, accepted= 10, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  296.00, terminal_time= 659.50 min, rate= 0.449/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  338.00, terminal_time= 676.50 min, rate= 0.500/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  326.00, terminal_time= 721.00 min, rate= 0.452/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  353.00, terminal_time= 700.00 min, rate= 0.504/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  336.00, terminal_time= 715.00 min, rate= 0.470/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 015] DRL:  R= 3387.87, T=1160.90m, Rate= 2.894/m, Acc=20.60 | HEUR: R= 2462.22, T=1014.20m, Rate= 2.391/m | PURE: R=  329.80, T= 694.40m, Rate= 0.475/m || pi=0.119 v=17.985 ent=0.009\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 2813.91, terminal_time=1081.50 min, rate= 2.602/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3622.30, terminal_time=1236.50 min, rate= 2.929/min, accepted= 26, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3377.12, terminal_time=1220.00 min, rate= 2.768/min, accepted= 23, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3688.01, terminal_time=1162.50 min, rate= 3.172/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 4090.48, terminal_time=1312.00 min, rate= 3.118/min, accepted= 23, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2626.12, terminal_time=1017.00 min, rate= 2.582/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2754.12, terminal_time=1071.50 min, rate= 2.570/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 1654.85, terminal_time= 848.00 min, rate= 1.951/min, accepted=  9, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 1742.73, terminal_time= 961.00 min, rate= 1.813/min, accepted= 10, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 1524.13, terminal_time= 822.50 min, rate= 1.853/min, accepted= 10, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  346.00, terminal_time= 695.00 min, rate= 0.498/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  301.00, terminal_time= 639.50 min, rate= 0.471/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  323.00, terminal_time= 671.50 min, rate= 0.481/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  353.00, terminal_time= 678.00 min, rate= 0.521/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  316.00, terminal_time= 696.00 min, rate= 0.454/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 020] DRL:  R= 3518.36, T=1202.50m, Rate= 2.918/m, Acc=22.00 | HEUR: R= 2060.39, T= 944.00m, Rate= 2.154/m | PURE: R=  327.80, T= 676.00m, Rate= 0.485/m || pi=-0.016 v=16.984 ent=0.008\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 4833.59, terminal_time=1440.00 min, rate= 3.357/min, accepted= 31, reason=horizon_reached\n",
      "    Ep02: reward= 2619.16, terminal_time= 995.50 min, rate= 2.631/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3300.59, terminal_time=1149.50 min, rate= 2.871/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3503.18, terminal_time=1240.50 min, rate= 2.824/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3195.70, terminal_time=1158.00 min, rate= 2.760/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 3065.33, terminal_time=1137.50 min, rate= 2.695/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3388.59, terminal_time=1218.00 min, rate= 2.782/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2326.12, terminal_time= 988.50 min, rate= 2.353/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 1979.20, terminal_time= 952.00 min, rate= 2.079/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2516.83, terminal_time=1012.50 min, rate= 2.486/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  318.00, terminal_time= 725.00 min, rate= 0.439/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  342.00, terminal_time= 699.00 min, rate= 0.489/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  325.00, terminal_time= 661.50 min, rate= 0.491/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  283.00, terminal_time= 611.00 min, rate= 0.463/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  351.00, terminal_time= 669.50 min, rate= 0.524/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 025] DRL:  R= 3490.44, T=1196.70m, Rate= 2.889/m, Acc=20.80 | HEUR: R= 2655.21, T=1061.70m, Rate= 2.479/m | PURE: R=  323.80, T= 673.20m, Rate= 0.481/m || pi=0.023 v=16.544 ent=0.007\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3847.62, terminal_time=1252.50 min, rate= 3.072/min, accepted= 25, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3137.92, terminal_time=1154.00 min, rate= 2.719/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 4293.75, terminal_time=1337.50 min, rate= 3.210/min, accepted= 26, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2911.57, terminal_time=1060.00 min, rate= 2.747/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3187.69, terminal_time=1174.00 min, rate= 2.715/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2350.28, terminal_time= 977.50 min, rate= 2.404/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 1687.75, terminal_time= 899.50 min, rate= 1.876/min, accepted= 10, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2012.97, terminal_time= 933.00 min, rate= 2.158/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2888.39, terminal_time=1089.00 min, rate= 2.652/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2215.30, terminal_time= 957.00 min, rate= 2.315/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  334.00, terminal_time= 700.00 min, rate= 0.477/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  280.00, terminal_time= 583.00 min, rate= 0.480/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  335.00, terminal_time= 695.50 min, rate= 0.482/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  310.00, terminal_time= 623.50 min, rate= 0.497/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  301.00, terminal_time= 644.00 min, rate= 0.467/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 030] DRL:  R= 3475.71, T=1195.60m, Rate= 2.893/m, Acc=22.00 | HEUR: R= 2230.94, T= 971.20m, Rate= 2.281/m | PURE: R=  312.00, T= 649.20m, Rate= 0.481/m || pi=-0.098 v=12.763 ent=0.002\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 2871.45, terminal_time=1059.50 min, rate= 2.710/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3180.04, terminal_time=1130.00 min, rate= 2.814/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3074.94, terminal_time=1126.50 min, rate= 2.730/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 5058.64, terminal_time=1440.00 min, rate= 3.513/min, accepted= 33, reason=horizon_reached\n",
      "    Ep05: reward= 2898.22, terminal_time=1064.50 min, rate= 2.723/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2997.07, terminal_time=1057.50 min, rate= 2.834/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 1516.33, terminal_time= 856.00 min, rate= 1.771/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2625.77, terminal_time=1036.50 min, rate= 2.533/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2452.68, terminal_time=1011.50 min, rate= 2.425/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3360.17, terminal_time=1174.50 min, rate= 2.861/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  338.00, terminal_time= 681.00 min, rate= 0.496/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  292.00, terminal_time= 620.50 min, rate= 0.471/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  339.00, terminal_time= 674.00 min, rate= 0.503/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  330.00, terminal_time= 679.00 min, rate= 0.486/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  304.00, terminal_time= 612.50 min, rate= 0.496/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 035] DRL:  R= 3416.66, T=1164.10m, Rate= 2.898/m, Acc=21.20 | HEUR: R= 2590.40, T=1027.20m, Rate= 2.485/m | PURE: R=  320.60, T= 653.40m, Rate= 0.490/m || pi=-0.019 v=21.240 ent=0.003\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3231.20, terminal_time=1167.50 min, rate= 2.768/min, accepted= 23, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2406.26, terminal_time=1092.00 min, rate= 2.204/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3090.12, terminal_time=1112.00 min, rate= 2.779/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 4083.08, terminal_time=1360.50 min, rate= 3.001/min, accepted= 27, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3335.28, terminal_time=1185.00 min, rate= 2.815/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 3095.43, terminal_time=1169.50 min, rate= 2.647/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 1771.64, terminal_time= 892.50 min, rate= 1.985/min, accepted= 11, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2531.90, terminal_time=1033.00 min, rate= 2.451/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3185.60, terminal_time=1119.00 min, rate= 2.847/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 1820.60, terminal_time= 918.00 min, rate= 1.983/min, accepted= 10, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  325.00, terminal_time= 648.00 min, rate= 0.502/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  321.00, terminal_time= 678.00 min, rate= 0.473/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  306.00, terminal_time= 672.00 min, rate= 0.455/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  332.00, terminal_time= 681.50 min, rate= 0.487/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  316.00, terminal_time= 663.50 min, rate= 0.476/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 040] DRL:  R= 3229.19, T=1183.40m, Rate= 2.713/m, Acc=20.80 | HEUR: R= 2481.03, T=1026.40m, Rate= 2.383/m | PURE: R=  320.00, T= 668.60m, Rate= 0.479/m || pi=0.054 v=18.541 ent=0.003\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3147.39, terminal_time=1155.50 min, rate= 2.724/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3870.03, terminal_time=1189.00 min, rate= 3.255/min, accepted= 24, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 4391.52, terminal_time=1301.50 min, rate= 3.374/min, accepted= 25, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2668.82, terminal_time=1036.00 min, rate= 2.576/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2255.65, terminal_time= 998.50 min, rate= 2.259/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 3090.57, terminal_time=1145.50 min, rate= 2.698/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2950.01, terminal_time=1075.00 min, rate= 2.744/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2594.90, terminal_time=1036.00 min, rate= 2.505/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3023.74, terminal_time=1085.00 min, rate= 2.787/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 1171.43, terminal_time= 834.00 min, rate= 1.405/min, accepted=  8, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  326.00, terminal_time= 697.00 min, rate= 0.468/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  329.00, terminal_time= 643.50 min, rate= 0.511/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  296.00, terminal_time= 658.00 min, rate= 0.450/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  311.00, terminal_time= 675.00 min, rate= 0.461/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  294.00, terminal_time= 728.50 min, rate= 0.404/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 045] DRL:  R= 3266.68, T=1136.10m, Rate= 2.838/m, Acc=19.20 | HEUR: R= 2566.13, T=1035.10m, Rate= 2.428/m | PURE: R=  311.20, T= 680.40m, Rate= 0.459/m || pi=-0.063 v=16.511 ent=0.003\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3775.69, terminal_time=1215.00 min, rate= 3.108/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3604.87, terminal_time=1192.00 min, rate= 3.024/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2467.41, terminal_time=1024.50 min, rate= 2.408/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2576.93, terminal_time=1012.00 min, rate= 2.546/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3506.09, terminal_time=1184.50 min, rate= 2.960/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2149.13, terminal_time= 980.50 min, rate= 2.192/min, accepted= 11, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2104.09, terminal_time= 968.50 min, rate= 2.173/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 1665.46, terminal_time= 937.00 min, rate= 1.777/min, accepted= 11, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3069.43, terminal_time=1173.00 min, rate= 2.617/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2036.48, terminal_time= 935.00 min, rate= 2.178/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  305.00, terminal_time= 672.50 min, rate= 0.454/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  348.00, terminal_time= 751.00 min, rate= 0.463/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  328.00, terminal_time= 652.50 min, rate= 0.503/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  300.00, terminal_time= 604.00 min, rate= 0.497/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  355.00, terminal_time= 705.00 min, rate= 0.504/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 050] DRL:  R= 3186.20, T=1125.60m, Rate= 2.809/m, Acc=18.40 | HEUR: R= 2204.92, T= 998.80m, Rate= 2.187/m | PURE: R=  327.20, T= 677.00m, Rate= 0.484/m || pi=-0.140 v=19.661 ent=0.002\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3861.56, terminal_time=1264.00 min, rate= 3.055/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2752.78, terminal_time=1000.50 min, rate= 2.751/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 4265.47, terminal_time=1268.50 min, rate= 3.363/min, accepted= 24, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3087.93, terminal_time=1117.50 min, rate= 2.763/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3063.62, terminal_time=1124.00 min, rate= 2.726/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 3269.46, terminal_time=1120.50 min, rate= 2.918/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2641.60, terminal_time=1087.50 min, rate= 2.429/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2780.37, terminal_time=1061.00 min, rate= 2.621/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2699.50, terminal_time=1119.50 min, rate= 2.411/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2764.46, terminal_time= 985.50 min, rate= 2.805/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  311.00, terminal_time= 655.00 min, rate= 0.475/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  326.00, terminal_time= 707.00 min, rate= 0.461/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  344.00, terminal_time= 664.50 min, rate= 0.518/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  340.00, terminal_time= 683.50 min, rate= 0.497/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  319.00, terminal_time= 659.50 min, rate= 0.484/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 055] DRL:  R= 3406.27, T=1154.90m, Rate= 2.932/m, Acc=19.00 | HEUR: R= 2831.08, T=1074.80m, Rate= 2.637/m | PURE: R=  328.00, T= 673.90m, Rate= 0.487/m || pi=-0.048 v=14.829 ent=0.001\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 2867.20, terminal_time=1084.00 min, rate= 2.645/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2984.02, terminal_time=1184.00 min, rate= 2.520/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3943.44, terminal_time=1280.50 min, rate= 3.080/min, accepted= 23, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3298.42, terminal_time=1228.00 min, rate= 2.686/min, accepted= 24, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3434.24, terminal_time=1158.00 min, rate= 2.966/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 1608.32, terminal_time= 871.00 min, rate= 1.847/min, accepted=  9, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2921.73, terminal_time=1153.50 min, rate= 2.533/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 1937.28, terminal_time= 941.50 min, rate= 2.058/min, accepted= 10, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3790.66, terminal_time=1221.50 min, rate= 3.103/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2462.71, terminal_time= 981.00 min, rate= 2.510/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  322.00, terminal_time= 692.50 min, rate= 0.465/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  297.00, terminal_time= 600.50 min, rate= 0.495/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  333.00, terminal_time= 703.00 min, rate= 0.474/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  327.00, terminal_time= 684.50 min, rate= 0.478/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  307.00, terminal_time= 657.50 min, rate= 0.467/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 060] DRL:  R= 3305.46, T=1186.90m, Rate= 2.779/m, Acc=20.80 | HEUR: R= 2544.14, T=1033.70m, Rate= 2.410/m | PURE: R=  317.20, T= 667.60m, Rate= 0.476/m || pi=-0.085 v=16.564 ent=0.005\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 4218.68, terminal_time=1328.00 min, rate= 3.177/min, accepted= 26, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3525.28, terminal_time=1231.00 min, rate= 2.864/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2726.11, terminal_time=1094.50 min, rate= 2.491/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3288.61, terminal_time=1142.00 min, rate= 2.880/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2193.93, terminal_time= 991.50 min, rate= 2.213/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2059.35, terminal_time=1001.00 min, rate= 2.057/min, accepted= 11, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2428.91, terminal_time=1020.50 min, rate= 2.380/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2962.75, terminal_time=1148.50 min, rate= 2.580/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2326.50, terminal_time=1034.50 min, rate= 2.249/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 1611.29, terminal_time= 853.50 min, rate= 1.888/min, accepted=  8, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  322.00, terminal_time= 655.50 min, rate= 0.491/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  321.00, terminal_time= 649.50 min, rate= 0.494/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  341.00, terminal_time= 677.00 min, rate= 0.504/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  326.00, terminal_time= 683.50 min, rate= 0.477/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  312.00, terminal_time= 641.50 min, rate= 0.486/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 065] DRL:  R= 3190.52, T=1157.40m, Rate= 2.725/m, Acc=19.00 | HEUR: R= 2277.76, T=1011.60m, Rate= 2.231/m | PURE: R=  324.40, T= 661.40m, Rate= 0.490/m || pi=0.031 v=13.000 ent=0.000\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3503.00, terminal_time=1179.00 min, rate= 2.971/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 4486.01, terminal_time=1393.00 min, rate= 3.220/min, accepted= 28, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2613.09, terminal_time=1089.50 min, rate= 2.398/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 4234.85, terminal_time=1287.50 min, rate= 3.289/min, accepted= 30, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 1726.89, terminal_time= 850.50 min, rate= 2.030/min, accepted=  8, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2605.54, terminal_time=1018.50 min, rate= 2.558/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 1437.19, terminal_time= 886.50 min, rate= 1.621/min, accepted=  8, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 1657.82, terminal_time= 922.00 min, rate= 1.798/min, accepted=  9, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 1871.26, terminal_time= 911.00 min, rate= 2.054/min, accepted= 11, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2376.84, terminal_time= 982.50 min, rate= 2.419/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  328.00, terminal_time= 667.00 min, rate= 0.492/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  291.00, terminal_time= 632.00 min, rate= 0.460/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  326.00, terminal_time= 635.50 min, rate= 0.513/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  343.00, terminal_time= 659.50 min, rate= 0.520/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  296.00, terminal_time= 647.00 min, rate= 0.457/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 070] DRL:  R= 3312.77, T=1159.90m, Rate= 2.782/m, Acc=21.00 | HEUR: R= 1989.73, T= 944.10m, Rate= 2.090/m | PURE: R=  316.80, T= 648.20m, Rate= 0.489/m || pi=0.168 v=17.156 ent=0.000\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 4265.73, terminal_time=1399.50 min, rate= 3.048/min, accepted= 33, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3546.24, terminal_time=1171.50 min, rate= 3.027/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3263.28, terminal_time=1126.50 min, rate= 2.897/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3865.14, terminal_time=1286.00 min, rate= 3.006/min, accepted= 23, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 4843.74, terminal_time=1415.50 min, rate= 3.422/min, accepted= 25, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 1518.54, terminal_time= 825.50 min, rate= 1.840/min, accepted=  9, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3221.14, terminal_time=1141.00 min, rate= 2.823/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2912.44, terminal_time=1126.50 min, rate= 2.585/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3736.85, terminal_time=1217.00 min, rate= 3.071/min, accepted= 24, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2262.22, terminal_time=1000.50 min, rate= 2.261/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  318.00, terminal_time= 655.00 min, rate= 0.485/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  329.00, terminal_time= 693.00 min, rate= 0.475/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  298.00, terminal_time= 630.50 min, rate= 0.473/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  315.00, terminal_time= 683.50 min, rate= 0.461/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  313.00, terminal_time= 663.50 min, rate= 0.472/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 075] DRL:  R= 3956.82, T=1279.80m, Rate= 3.080/m, Acc=23.40 | HEUR: R= 2730.24, T=1062.10m, Rate= 2.516/m | PURE: R=  314.60, T= 665.10m, Rate= 0.473/m || pi=-0.007 v=16.303 ent=0.003\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3155.02, terminal_time=1132.00 min, rate= 2.787/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 4900.41, terminal_time=1438.00 min, rate= 3.408/min, accepted= 26, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 1717.74, terminal_time= 921.00 min, rate= 1.865/min, accepted=  9, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 4827.25, terminal_time=1419.00 min, rate= 3.402/min, accepted= 31, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 4566.72, terminal_time=1336.00 min, rate= 3.418/min, accepted= 26, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2473.03, terminal_time=1025.00 min, rate= 2.413/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3511.53, terminal_time=1221.50 min, rate= 2.875/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2898.19, terminal_time=1077.00 min, rate= 2.691/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2843.24, terminal_time=1086.50 min, rate= 2.617/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 1929.48, terminal_time= 926.00 min, rate= 2.084/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  290.00, terminal_time= 637.50 min, rate= 0.455/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  331.00, terminal_time= 633.50 min, rate= 0.522/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  299.00, terminal_time= 650.00 min, rate= 0.460/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  337.00, terminal_time= 666.50 min, rate= 0.506/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  304.00, terminal_time= 667.50 min, rate= 0.455/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 080] DRL:  R= 3833.43, T=1249.20m, Rate= 2.976/m, Acc=22.00 | HEUR: R= 2731.09, T=1067.20m, Rate= 2.536/m | PURE: R=  312.20, T= 651.00m, Rate= 0.480/m || pi=0.158 v=18.968 ent=0.001\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 2101.46, terminal_time= 914.00 min, rate= 2.299/min, accepted= 11, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 4663.67, terminal_time=1292.00 min, rate= 3.610/min, accepted= 26, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3998.02, terminal_time=1225.00 min, rate= 3.264/min, accepted= 25, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3373.16, terminal_time=1213.00 min, rate= 2.781/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 1991.87, terminal_time= 893.50 min, rate= 2.229/min, accepted= 11, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2295.65, terminal_time=1011.00 min, rate= 2.271/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 1694.78, terminal_time= 897.50 min, rate= 1.888/min, accepted=  8, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2941.33, terminal_time=1126.00 min, rate= 2.612/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2523.75, terminal_time=1039.00 min, rate= 2.429/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2836.58, terminal_time=1141.50 min, rate= 2.485/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  315.00, terminal_time= 645.00 min, rate= 0.488/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  337.00, terminal_time= 735.50 min, rate= 0.458/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  327.00, terminal_time= 706.50 min, rate= 0.463/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  295.00, terminal_time= 626.50 min, rate= 0.471/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  327.00, terminal_time= 640.00 min, rate= 0.511/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 085] DRL:  R= 3225.64, T=1107.50m, Rate= 2.837/m, Acc=18.40 | HEUR: R= 2458.42, T=1043.00m, Rate= 2.337/m | PURE: R=  320.20, T= 670.70m, Rate= 0.478/m || pi=0.047 v=16.387 ent=0.004\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 5383.61, terminal_time=1440.00 min, rate= 3.739/min, accepted= 32, reason=horizon_reached\n",
      "    Ep02: reward= 4076.60, terminal_time=1320.50 min, rate= 3.087/min, accepted= 24, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3342.66, terminal_time=1191.00 min, rate= 2.807/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2725.08, terminal_time=1020.50 min, rate= 2.670/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2119.03, terminal_time= 972.00 min, rate= 2.180/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2089.81, terminal_time= 986.50 min, rate= 2.118/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2449.75, terminal_time= 989.50 min, rate= 2.476/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 1931.02, terminal_time= 942.50 min, rate= 2.049/min, accepted= 10, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2287.26, terminal_time= 956.50 min, rate= 2.391/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 1413.55, terminal_time= 924.00 min, rate= 1.530/min, accepted=  8, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  328.00, terminal_time= 685.00 min, rate= 0.479/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  310.00, terminal_time= 715.50 min, rate= 0.433/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  334.00, terminal_time= 692.50 min, rate= 0.482/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  318.00, terminal_time= 655.50 min, rate= 0.485/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  308.00, terminal_time= 672.50 min, rate= 0.458/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 090] DRL:  R= 3529.40, T=1188.80m, Rate= 2.897/m, Acc=20.80 | HEUR: R= 2034.28, T= 959.80m, Rate= 2.113/m | PURE: R=  319.60, T= 684.20m, Rate= 0.468/m || pi=-0.065 v=24.170 ent=0.002\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 4895.60, terminal_time=1440.00 min, rate= 3.400/min, accepted= 30, reason=horizon_reached\n",
      "    Ep02: reward= 3139.20, terminal_time=1034.50 min, rate= 3.035/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3660.27, terminal_time=1218.50 min, rate= 3.004/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3706.89, terminal_time=1140.50 min, rate= 3.250/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 5178.76, terminal_time=1440.00 min, rate= 3.596/min, accepted= 27, reason=horizon_reached\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 1679.41, terminal_time= 941.50 min, rate= 1.784/min, accepted=  9, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 4173.38, terminal_time=1246.00 min, rate= 3.349/min, accepted= 24, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 1856.19, terminal_time= 923.00 min, rate= 2.011/min, accepted= 11, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2153.19, terminal_time= 971.50 min, rate= 2.216/min, accepted= 11, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2232.08, terminal_time= 981.00 min, rate= 2.275/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  321.00, terminal_time= 628.50 min, rate= 0.511/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  313.00, terminal_time= 659.50 min, rate= 0.475/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  331.00, terminal_time= 660.50 min, rate= 0.501/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  328.00, terminal_time= 754.50 min, rate= 0.435/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  318.00, terminal_time= 703.50 min, rate= 0.452/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 095] DRL:  R= 4116.15, T=1254.70m, Rate= 3.257/m, Acc=23.20 | HEUR: R= 2418.85, T=1012.60m, Rate= 2.327/m | PURE: R=  322.20, T= 681.30m, Rate= 0.475/m || pi=-0.011 v=13.096 ent=0.001\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 2596.08, terminal_time=1033.00 min, rate= 2.513/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 4415.36, terminal_time=1340.00 min, rate= 3.295/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3625.60, terminal_time=1205.00 min, rate= 3.009/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 4002.54, terminal_time=1288.50 min, rate= 3.106/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3075.49, terminal_time=1147.00 min, rate= 2.681/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 1536.37, terminal_time= 947.00 min, rate= 1.622/min, accepted=  9, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2442.30, terminal_time=1045.00 min, rate= 2.337/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2923.63, terminal_time=1071.00 min, rate= 2.730/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 1829.96, terminal_time= 922.00 min, rate= 1.985/min, accepted= 11, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2694.39, terminal_time=1033.50 min, rate= 2.607/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  347.00, terminal_time= 687.00 min, rate= 0.505/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  315.00, terminal_time= 643.50 min, rate= 0.490/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  331.00, terminal_time= 753.50 min, rate= 0.439/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  329.00, terminal_time= 649.50 min, rate= 0.507/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  313.00, terminal_time= 660.50 min, rate= 0.474/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 100] DRL:  R= 3543.01, T=1202.70m, Rate= 2.921/m, Acc=18.80 | HEUR: R= 2285.33, T=1003.70m, Rate= 2.256/m | PURE: R=  327.00, T= 678.80m, Rate= 0.483/m || pi=0.019 v=11.789 ent=0.002\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 2354.79, terminal_time= 942.50 min, rate= 2.498/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3658.39, terminal_time=1225.00 min, rate= 2.986/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3213.77, terminal_time=1161.00 min, rate= 2.768/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3488.39, terminal_time=1139.00 min, rate= 3.063/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 4068.90, terminal_time=1311.00 min, rate= 3.104/min, accepted= 24, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2934.44, terminal_time=1176.00 min, rate= 2.495/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2932.24, terminal_time=1063.00 min, rate= 2.758/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2055.87, terminal_time= 979.50 min, rate= 2.099/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3107.13, terminal_time=1097.50 min, rate= 2.831/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 1331.39, terminal_time= 759.00 min, rate= 1.754/min, accepted=  7, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  344.00, terminal_time= 676.50 min, rate= 0.508/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  311.00, terminal_time= 662.00 min, rate= 0.470/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  328.00, terminal_time= 699.00 min, rate= 0.469/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  347.00, terminal_time= 733.00 min, rate= 0.473/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  310.00, terminal_time= 656.00 min, rate= 0.473/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 105] DRL:  R= 3356.85, T=1155.70m, Rate= 2.884/m, Acc=19.20 | HEUR: R= 2472.21, T=1015.00m, Rate= 2.388/m | PURE: R=  328.00, T= 685.30m, Rate= 0.479/m || pi=-0.018 v=20.087 ent=0.001\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 4180.10, terminal_time=1285.00 min, rate= 3.253/min, accepted= 25, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2427.07, terminal_time=1001.50 min, rate= 2.423/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2862.48, terminal_time=1096.00 min, rate= 2.612/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2627.04, terminal_time=1108.50 min, rate= 2.370/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 4168.52, terminal_time=1364.00 min, rate= 3.056/min, accepted= 24, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2821.23, terminal_time=1087.00 min, rate= 2.595/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2644.09, terminal_time=1060.50 min, rate= 2.493/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2857.06, terminal_time=1098.50 min, rate= 2.601/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3014.45, terminal_time=1039.50 min, rate= 2.900/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2438.79, terminal_time=1032.00 min, rate= 2.363/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  308.00, terminal_time= 622.00 min, rate= 0.495/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  324.00, terminal_time= 683.50 min, rate= 0.474/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  340.00, terminal_time= 733.50 min, rate= 0.464/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  319.00, terminal_time= 668.50 min, rate= 0.477/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  334.00, terminal_time= 685.00 min, rate= 0.488/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 110] DRL:  R= 3253.04, T=1171.00m, Rate= 2.743/m, Acc=19.40 | HEUR: R= 2755.12, T=1063.50m, Rate= 2.591/m | PURE: R=  325.00, T= 678.50m, Rate= 0.480/m || pi=0.011 v=19.414 ent=0.002\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3562.73, terminal_time=1254.50 min, rate= 2.840/min, accepted= 23, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3651.33, terminal_time=1181.00 min, rate= 3.092/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2012.23, terminal_time= 963.50 min, rate= 2.088/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 1506.99, terminal_time= 835.50 min, rate= 1.804/min, accepted=  9, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3343.55, terminal_time=1125.50 min, rate= 2.971/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 3247.48, terminal_time=1188.00 min, rate= 2.734/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2381.97, terminal_time= 990.00 min, rate= 2.406/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3268.50, terminal_time=1200.50 min, rate= 2.723/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2704.21, terminal_time=1035.50 min, rate= 2.612/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2485.14, terminal_time=1058.00 min, rate= 2.349/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  315.00, terminal_time= 641.00 min, rate= 0.491/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  316.00, terminal_time= 665.00 min, rate= 0.475/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  335.00, terminal_time= 731.00 min, rate= 0.458/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  334.00, terminal_time= 684.50 min, rate= 0.488/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  324.00, terminal_time= 656.00 min, rate= 0.494/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 115] DRL:  R= 2815.37, T=1072.00m, Rate= 2.559/m, Acc=17.00 | HEUR: R= 2817.46, T=1094.40m, Rate= 2.565/m | PURE: R=  324.80, T= 675.50m, Rate= 0.481/m || pi=0.031 v=15.387 ent=0.004\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3843.45, terminal_time=1194.00 min, rate= 3.219/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3612.25, terminal_time=1243.50 min, rate= 2.905/min, accepted= 23, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2385.39, terminal_time= 999.00 min, rate= 2.388/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2465.95, terminal_time=1042.00 min, rate= 2.367/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2269.84, terminal_time= 929.50 min, rate= 2.442/min, accepted= 11, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 3161.25, terminal_time=1177.50 min, rate= 2.685/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2800.61, terminal_time=1052.00 min, rate= 2.662/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2390.71, terminal_time=1008.00 min, rate= 2.372/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2973.61, terminal_time=1129.00 min, rate= 2.634/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2509.83, terminal_time=1096.00 min, rate= 2.290/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  302.00, terminal_time= 643.00 min, rate= 0.470/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  330.00, terminal_time= 664.00 min, rate= 0.497/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  332.00, terminal_time= 635.50 min, rate= 0.522/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  324.00, terminal_time= 666.50 min, rate= 0.486/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  306.00, terminal_time= 616.50 min, rate= 0.496/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 120] DRL:  R= 2915.37, T=1081.60m, Rate= 2.664/m, Acc=16.80 | HEUR: R= 2767.20, T=1092.50m, Rate= 2.528/m | PURE: R=  318.80, T= 645.10m, Rate= 0.494/m || pi=0.050 v=13.445 ent=0.003\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3147.49, terminal_time=1144.50 min, rate= 2.750/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2733.63, terminal_time=1085.00 min, rate= 2.519/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 5523.30, terminal_time=1440.00 min, rate= 3.836/min, accepted= 31, reason=horizon_reached\n",
      "    Ep04: reward= 2930.70, terminal_time=1117.50 min, rate= 2.623/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2451.36, terminal_time= 960.50 min, rate= 2.552/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2303.60, terminal_time= 987.50 min, rate= 2.333/min, accepted= 11, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 1313.07, terminal_time= 827.50 min, rate= 1.587/min, accepted=  8, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2152.66, terminal_time= 953.00 min, rate= 2.259/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3521.89, terminal_time=1199.00 min, rate= 2.937/min, accepted= 22, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2614.58, terminal_time=1024.00 min, rate= 2.553/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  307.00, terminal_time= 639.50 min, rate= 0.480/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  299.00, terminal_time= 723.00 min, rate= 0.414/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  304.00, terminal_time= 626.50 min, rate= 0.485/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  331.00, terminal_time= 678.50 min, rate= 0.488/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  348.00, terminal_time= 677.00 min, rate= 0.514/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 125] DRL:  R= 3357.30, T=1149.50m, Rate= 2.856/m, Acc=19.40 | HEUR: R= 2381.16, T= 998.20m, Rate= 2.334/m | PURE: R=  317.80, T= 668.90m, Rate= 0.476/m || pi=0.150 v=18.554 ent=0.007\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 2879.41, terminal_time=1116.50 min, rate= 2.579/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3238.73, terminal_time=1199.50 min, rate= 2.700/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2218.60, terminal_time=1009.00 min, rate= 2.199/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3660.89, terminal_time=1242.50 min, rate= 2.946/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2318.59, terminal_time= 948.00 min, rate= 2.446/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 1858.86, terminal_time= 933.50 min, rate= 1.991/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 1650.60, terminal_time= 851.00 min, rate= 1.940/min, accepted= 10, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 1544.04, terminal_time= 872.50 min, rate= 1.770/min, accepted=  9, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3335.14, terminal_time=1112.00 min, rate= 2.999/min, accepted= 22, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 1447.35, terminal_time= 870.50 min, rate= 1.663/min, accepted=  7, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  306.00, terminal_time= 681.50 min, rate= 0.449/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  303.00, terminal_time= 639.50 min, rate= 0.474/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  307.00, terminal_time= 672.00 min, rate= 0.457/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  325.00, terminal_time= 687.00 min, rate= 0.473/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  333.00, terminal_time= 736.00 min, rate= 0.452/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 130] DRL:  R= 2863.24, T=1103.10m, Rate= 2.574/m, Acc=18.00 | HEUR: R= 1967.20, T= 927.90m, Rate= 2.072/m | PURE: R=  314.80, T= 683.20m, Rate= 0.461/m || pi=0.010 v=16.018 ent=0.002\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 2305.85, terminal_time= 981.00 min, rate= 2.351/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3310.40, terminal_time=1085.00 min, rate= 3.051/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 4059.61, terminal_time=1236.50 min, rate= 3.283/min, accepted= 26, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 4129.06, terminal_time=1263.00 min, rate= 3.269/min, accepted= 25, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3695.05, terminal_time=1278.50 min, rate= 2.890/min, accepted= 22, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 1139.69, terminal_time= 800.50 min, rate= 1.424/min, accepted=  7, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3216.52, terminal_time=1118.50 min, rate= 2.876/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2647.23, terminal_time=1050.50 min, rate= 2.520/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3234.55, terminal_time=1170.00 min, rate= 2.765/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2259.64, terminal_time= 988.50 min, rate= 2.286/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  360.00, terminal_time= 727.50 min, rate= 0.495/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  334.00, terminal_time= 736.00 min, rate= 0.454/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  315.00, terminal_time= 679.00 min, rate= 0.464/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  338.00, terminal_time= 661.50 min, rate= 0.511/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  314.00, terminal_time= 664.50 min, rate= 0.473/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 135] DRL:  R= 3499.99, T=1168.80m, Rate= 2.969/m, Acc=21.60 | HEUR: R= 2499.53, T=1025.60m, Rate= 2.374/m | PURE: R=  332.20, T= 693.70m, Rate= 0.479/m || pi=0.140 v=12.475 ent=0.001\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 2607.21, terminal_time= 980.00 min, rate= 2.660/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2497.47, terminal_time=1004.50 min, rate= 2.486/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3044.06, terminal_time=1063.50 min, rate= 2.862/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2321.19, terminal_time= 997.50 min, rate= 2.327/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3016.65, terminal_time=1075.00 min, rate= 2.806/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 3838.04, terminal_time=1306.00 min, rate= 2.939/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 1757.33, terminal_time= 938.00 min, rate= 1.873/min, accepted= 10, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2867.48, terminal_time=1090.00 min, rate= 2.631/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2926.05, terminal_time=1153.50 min, rate= 2.537/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2865.23, terminal_time=1063.00 min, rate= 2.695/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  303.00, terminal_time= 620.00 min, rate= 0.489/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  324.00, terminal_time= 681.50 min, rate= 0.475/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  278.00, terminal_time= 635.50 min, rate= 0.437/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  311.00, terminal_time= 626.00 min, rate= 0.497/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  301.00, terminal_time= 632.50 min, rate= 0.476/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 140] DRL:  R= 2697.31, T=1024.10m, Rate= 2.628/m, Acc=16.20 | HEUR: R= 2850.82, T=1110.10m, Rate= 2.535/m | PURE: R=  303.40, T= 639.10m, Rate= 0.475/m || pi=-0.067 v=15.056 ent=0.005\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 2873.61, terminal_time=1145.00 min, rate= 2.510/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3812.87, terminal_time=1240.50 min, rate= 3.074/min, accepted= 23, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2427.27, terminal_time=1023.00 min, rate= 2.373/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2615.80, terminal_time= 984.50 min, rate= 2.657/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3532.64, terminal_time=1179.50 min, rate= 2.995/min, accepted= 22, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2410.67, terminal_time=1030.00 min, rate= 2.340/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 1604.16, terminal_time= 968.50 min, rate= 1.656/min, accepted=  7, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 1741.33, terminal_time= 916.00 min, rate= 1.901/min, accepted= 11, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2047.39, terminal_time= 980.00 min, rate= 2.089/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2878.24, terminal_time=1096.50 min, rate= 2.625/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  327.00, terminal_time= 699.00 min, rate= 0.468/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  336.00, terminal_time= 672.50 min, rate= 0.500/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  330.00, terminal_time= 685.00 min, rate= 0.482/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  315.00, terminal_time= 704.50 min, rate= 0.447/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  304.00, terminal_time= 667.50 min, rate= 0.455/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 145] DRL:  R= 3052.44, T=1114.50m, Rate= 2.722/m, Acc=19.40 | HEUR: R= 2136.36, T= 998.20m, Rate= 2.122/m | PURE: R=  322.40, T= 685.70m, Rate= 0.470/m || pi=0.064 v=11.796 ent=0.008\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 2493.15, terminal_time=1004.00 min, rate= 2.483/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2786.10, terminal_time=1091.00 min, rate= 2.554/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 4175.98, terminal_time=1259.50 min, rate= 3.316/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2312.69, terminal_time=1018.50 min, rate= 2.271/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3183.38, terminal_time=1183.00 min, rate= 2.691/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2268.12, terminal_time=1019.00 min, rate= 2.226/min, accepted= 11, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3253.35, terminal_time=1135.50 min, rate= 2.865/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2322.91, terminal_time=1011.00 min, rate= 2.298/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2667.18, terminal_time=1007.50 min, rate= 2.647/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3504.08, terminal_time=1167.50 min, rate= 3.001/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  311.00, terminal_time= 647.50 min, rate= 0.480/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  303.00, terminal_time= 658.00 min, rate= 0.460/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  340.00, terminal_time= 697.50 min, rate= 0.487/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  341.00, terminal_time= 679.50 min, rate= 0.502/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  300.00, terminal_time= 642.00 min, rate= 0.467/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 150] DRL:  R= 2990.26, T=1111.20m, Rate= 2.663/m, Acc=16.60 | HEUR: R= 2803.13, T=1068.10m, Rate= 2.607/m | PURE: R=  319.00, T= 664.90m, Rate= 0.479/m || pi=-0.091 v=20.579 ent=0.007\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3360.27, terminal_time=1210.50 min, rate= 2.776/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 4415.73, terminal_time=1365.50 min, rate= 3.234/min, accepted= 32, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2585.58, terminal_time=1011.00 min, rate= 2.557/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 4850.11, terminal_time=1440.00 min, rate= 3.368/min, accepted= 33, reason=horizon_reached\n",
      "    Ep05: reward= 4220.37, terminal_time=1301.50 min, rate= 3.243/min, accepted= 24, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2704.73, terminal_time= 996.50 min, rate= 2.714/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3166.34, terminal_time=1160.00 min, rate= 2.730/min, accepted= 22, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2970.42, terminal_time=1077.50 min, rate= 2.757/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2436.19, terminal_time=1015.50 min, rate= 2.399/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2969.38, terminal_time=1155.00 min, rate= 2.571/min, accepted= 22, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  309.00, terminal_time= 662.50 min, rate= 0.466/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  291.00, terminal_time= 612.00 min, rate= 0.475/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  291.00, terminal_time= 649.50 min, rate= 0.448/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  328.00, terminal_time= 662.50 min, rate= 0.495/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  341.00, terminal_time= 740.00 min, rate= 0.461/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 155] DRL:  R= 3886.41, T=1265.70m, Rate= 3.036/m, Acc=25.00 | HEUR: R= 2849.41, T=1080.90m, Rate= 2.634/m | PURE: R=  312.00, T= 665.30m, Rate= 0.469/m || pi=-0.031 v=20.832 ent=0.008\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3560.43, terminal_time=1215.50 min, rate= 2.929/min, accepted= 25, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3942.58, terminal_time=1250.00 min, rate= 3.154/min, accepted= 23, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2277.78, terminal_time=1034.00 min, rate= 2.203/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3399.74, terminal_time=1170.00 min, rate= 2.906/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 5328.53, terminal_time=1440.00 min, rate= 3.700/min, accepted= 29, reason=horizon_reached\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2310.72, terminal_time=1050.50 min, rate= 2.200/min, accepted= 11, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3354.14, terminal_time=1171.50 min, rate= 2.863/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2027.60, terminal_time= 953.50 min, rate= 2.126/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2153.62, terminal_time=1003.50 min, rate= 2.146/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2147.78, terminal_time= 929.00 min, rate= 2.312/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  301.00, terminal_time= 669.50 min, rate= 0.450/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  301.00, terminal_time= 608.50 min, rate= 0.495/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  308.00, terminal_time= 635.50 min, rate= 0.485/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  335.00, terminal_time= 740.50 min, rate= 0.452/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  355.00, terminal_time= 705.00 min, rate= 0.504/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 160] DRL:  R= 3701.81, T=1221.90m, Rate= 2.978/m, Acc=22.20 | HEUR: R= 2398.77, T=1021.60m, Rate= 2.329/m | PURE: R=  320.00, T= 671.80m, Rate= 0.477/m || pi=0.018 v=13.617 ent=0.002\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3978.58, terminal_time=1184.50 min, rate= 3.359/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3546.11, terminal_time=1163.00 min, rate= 3.049/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2807.64, terminal_time=1048.50 min, rate= 2.678/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3708.57, terminal_time=1209.00 min, rate= 3.067/min, accepted= 26, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 1188.41, terminal_time= 752.50 min, rate= 1.579/min, accepted=  7, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2821.99, terminal_time=1122.00 min, rate= 2.515/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3403.02, terminal_time=1173.00 min, rate= 2.901/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2875.26, terminal_time=1118.50 min, rate= 2.571/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2652.62, terminal_time=1043.00 min, rate= 2.543/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2005.63, terminal_time= 863.00 min, rate= 2.324/min, accepted= 10, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  330.00, terminal_time= 676.50 min, rate= 0.488/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  309.00, terminal_time= 660.00 min, rate= 0.468/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  314.00, terminal_time= 671.50 min, rate= 0.468/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  325.00, terminal_time= 657.50 min, rate= 0.494/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  320.00, terminal_time= 636.00 min, rate= 0.503/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 165] DRL:  R= 3045.86, T=1071.50m, Rate= 2.746/m, Acc=18.20 | HEUR: R= 2751.70, T=1063.90m, Rate= 2.571/m | PURE: R=  319.60, T= 660.30m, Rate= 0.484/m || pi=0.002 v=12.049 ent=0.006\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3229.59, terminal_time=1162.00 min, rate= 2.779/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2672.68, terminal_time=1043.00 min, rate= 2.562/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2830.42, terminal_time=1147.50 min, rate= 2.467/min, accepted= 22, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2697.90, terminal_time=1011.00 min, rate= 2.669/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2976.46, terminal_time=1081.00 min, rate= 2.753/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2197.12, terminal_time=1001.00 min, rate= 2.195/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2167.38, terminal_time= 983.00 min, rate= 2.205/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2047.35, terminal_time= 954.50 min, rate= 2.145/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3296.48, terminal_time=1111.00 min, rate= 2.967/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 1877.80, terminal_time= 914.00 min, rate= 2.054/min, accepted=  9, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  350.00, terminal_time= 717.50 min, rate= 0.488/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  359.00, terminal_time= 737.00 min, rate= 0.487/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  313.00, terminal_time= 676.00 min, rate= 0.463/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  293.00, terminal_time= 643.00 min, rate= 0.456/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  329.00, terminal_time= 691.00 min, rate= 0.476/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 170] DRL:  R= 2881.41, T=1088.90m, Rate= 2.646/m, Acc=17.60 | HEUR: R= 2317.23, T= 992.70m, Rate= 2.313/m | PURE: R=  328.80, T= 692.90m, Rate= 0.474/m || pi=0.058 v=19.407 ent=0.004\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3715.60, terminal_time=1312.00 min, rate= 2.832/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2592.93, terminal_time=1027.50 min, rate= 2.524/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 4616.79, terminal_time=1299.50 min, rate= 3.553/min, accepted= 23, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3156.02, terminal_time=1238.50 min, rate= 2.548/min, accepted= 23, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2765.24, terminal_time=1044.00 min, rate= 2.649/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2473.24, terminal_time=1033.50 min, rate= 2.393/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3206.82, terminal_time=1124.00 min, rate= 2.853/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2259.47, terminal_time=1067.00 min, rate= 2.118/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 1481.72, terminal_time= 929.00 min, rate= 1.595/min, accepted=  9, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 1733.37, terminal_time= 937.50 min, rate= 1.849/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  309.00, terminal_time= 654.50 min, rate= 0.472/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  321.00, terminal_time= 639.50 min, rate= 0.502/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  333.00, terminal_time= 660.00 min, rate= 0.505/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  330.00, terminal_time= 679.00 min, rate= 0.486/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  298.00, terminal_time= 674.50 min, rate= 0.442/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 175] DRL:  R= 3369.32, T=1184.30m, Rate= 2.821/m, Acc=19.60 | HEUR: R= 2230.92, T=1018.20m, Rate= 2.162/m | PURE: R=  318.20, T= 661.50m, Rate= 0.481/m || pi=0.094 v=17.515 ent=0.006\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 2636.47, terminal_time=1036.00 min, rate= 2.545/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3900.61, terminal_time=1337.00 min, rate= 2.917/min, accepted= 23, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 4168.77, terminal_time=1315.50 min, rate= 3.169/min, accepted= 24, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3108.81, terminal_time=1135.50 min, rate= 2.738/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3544.16, terminal_time=1180.00 min, rate= 3.004/min, accepted= 22, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2381.81, terminal_time=1058.00 min, rate= 2.251/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2280.24, terminal_time= 937.50 min, rate= 2.432/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 1809.40, terminal_time= 959.00 min, rate= 1.887/min, accepted= 11, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 1738.33, terminal_time= 946.50 min, rate= 1.837/min, accepted= 10, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2911.65, terminal_time=1090.00 min, rate= 2.671/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  309.00, terminal_time= 663.50 min, rate= 0.466/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  329.00, terminal_time= 649.00 min, rate= 0.507/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  303.00, terminal_time= 610.50 min, rate= 0.496/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  299.00, terminal_time= 692.00 min, rate= 0.432/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  321.00, terminal_time= 758.00 min, rate= 0.423/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 180] DRL:  R= 3471.76, T=1200.80m, Rate= 2.875/m, Acc=20.40 | HEUR: R= 2224.29, T= 998.20m, Rate= 2.216/m | PURE: R=  312.20, T= 674.60m, Rate= 0.465/m || pi=0.050 v=14.424 ent=0.005\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3187.89, terminal_time=1270.00 min, rate= 2.510/min, accepted= 25, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 1972.32, terminal_time= 881.50 min, rate= 2.237/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3098.63, terminal_time=1198.50 min, rate= 2.585/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2811.75, terminal_time=1089.00 min, rate= 2.582/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3771.12, terminal_time=1204.00 min, rate= 3.132/min, accepted= 26, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 1518.16, terminal_time= 875.50 min, rate= 1.734/min, accepted= 10, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3689.41, terminal_time=1198.00 min, rate= 3.080/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3094.84, terminal_time=1120.50 min, rate= 2.762/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 1740.19, terminal_time= 922.50 min, rate= 1.886/min, accepted=  8, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2416.62, terminal_time= 992.50 min, rate= 2.435/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  318.00, terminal_time= 681.50 min, rate= 0.467/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  320.00, terminal_time= 675.00 min, rate= 0.474/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  307.00, terminal_time= 633.50 min, rate= 0.485/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  323.00, terminal_time= 660.00 min, rate= 0.489/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  341.00, terminal_time= 716.00 min, rate= 0.476/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 185] DRL:  R= 2968.34, T=1128.60m, Rate= 2.609/m, Acc=20.80 | HEUR: R= 2491.85, T=1021.80m, Rate= 2.379/m | PURE: R=  321.80, T= 673.20m, Rate= 0.478/m || pi=-0.002 v=17.396 ent=0.007\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3683.47, terminal_time=1222.50 min, rate= 3.013/min, accepted= 23, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3693.73, terminal_time=1269.00 min, rate= 2.911/min, accepted= 23, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 4350.68, terminal_time=1291.00 min, rate= 3.370/min, accepted= 26, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2641.74, terminal_time=1043.00 min, rate= 2.533/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3230.51, terminal_time=1159.50 min, rate= 2.786/min, accepted= 24, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 3236.15, terminal_time=1095.00 min, rate= 2.955/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3632.36, terminal_time=1216.50 min, rate= 2.986/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 2311.71, terminal_time=1017.00 min, rate= 2.273/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2643.52, terminal_time=1038.50 min, rate= 2.546/min, accepted= 14, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3940.48, terminal_time=1293.50 min, rate= 3.046/min, accepted= 22, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  314.00, terminal_time= 718.50 min, rate= 0.437/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  327.00, terminal_time= 684.00 min, rate= 0.478/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  304.00, terminal_time= 659.00 min, rate= 0.461/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  309.00, terminal_time= 647.50 min, rate= 0.477/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  345.00, terminal_time= 711.00 min, rate= 0.485/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 190] DRL:  R= 3520.02, T=1197.00m, Rate= 2.923/m, Acc=22.60 | HEUR: R= 3152.84, T=1132.10m, Rate= 2.761/m | PURE: R=  319.80, T= 684.00m, Rate= 0.468/m || pi=0.108 v=14.168 ent=0.007\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3645.58, terminal_time=1204.00 min, rate= 3.028/min, accepted= 22, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 5390.84, terminal_time=1440.00 min, rate= 3.744/min, accepted= 33, reason=horizon_reached\n",
      "    Ep03: reward= 4018.98, terminal_time=1308.50 min, rate= 3.071/min, accepted= 26, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 3520.26, terminal_time=1176.50 min, rate= 2.992/min, accepted= 21, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2513.55, terminal_time=1055.50 min, rate= 2.381/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 2278.82, terminal_time= 970.50 min, rate= 2.348/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3134.56, terminal_time=1167.00 min, rate= 2.686/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 1843.14, terminal_time= 983.00 min, rate= 1.875/min, accepted= 13, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2664.80, terminal_time=1098.00 min, rate= 2.427/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2965.99, terminal_time=1071.00 min, rate= 2.769/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  327.00, terminal_time= 681.50 min, rate= 0.480/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  314.00, terminal_time= 652.50 min, rate= 0.481/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  293.00, terminal_time= 621.00 min, rate= 0.472/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  302.00, terminal_time= 660.00 min, rate= 0.458/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  310.00, terminal_time= 662.00 min, rate= 0.468/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 195] DRL:  R= 3817.84, T=1236.90m, Rate= 3.043/m, Acc=24.20 | HEUR: R= 2577.46, T=1057.90m, Rate= 2.421/m | PURE: R=  309.20, T= 655.40m, Rate= 0.472/m || pi=-0.098 v=17.612 ent=0.008\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3737.85, terminal_time=1207.00 min, rate= 3.097/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3898.74, terminal_time=1195.00 min, rate= 3.263/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3013.07, terminal_time=1179.50 min, rate= 2.555/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 4428.01, terminal_time=1345.50 min, rate= 3.291/min, accepted= 27, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3666.64, terminal_time=1218.00 min, rate= 3.010/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 1037.30, terminal_time= 719.50 min, rate= 1.442/min, accepted=  7, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 2278.03, terminal_time= 950.00 min, rate= 2.398/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3556.81, terminal_time=1221.50 min, rate= 2.912/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2743.66, terminal_time=1111.00 min, rate= 2.470/min, accepted= 15, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3156.83, terminal_time=1122.50 min, rate= 2.812/min, accepted= 19, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  300.00, terminal_time= 621.50 min, rate= 0.483/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  347.00, terminal_time= 694.50 min, rate= 0.500/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  323.00, terminal_time= 668.00 min, rate= 0.484/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  317.00, terminal_time= 705.00 min, rate= 0.450/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  315.00, terminal_time= 646.50 min, rate= 0.487/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "[Upd 200] DRL:  R= 3748.86, T=1229.00m, Rate= 3.043/m, Acc=20.60 | HEUR: R= 2554.53, T=1024.90m, Rate= 2.407/m | PURE: R=  320.40, T= 667.10m, Rate= 0.481/m || pi=0.044 v=11.770 ent=0.007\n",
      "  DRL  episodes:\n",
      "    Ep01: reward= 3890.27, terminal_time=1269.50 min, rate= 3.064/min, accepted= 27, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3949.10, terminal_time=1318.00 min, rate= 2.996/min, accepted= 24, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 3836.47, terminal_time=1218.50 min, rate= 3.149/min, accepted= 20, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 2558.15, terminal_time=1024.00 min, rate= 2.498/min, accepted= 16, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 3505.36, terminal_time=1200.00 min, rate= 2.921/min, accepted= 24, reason=packages_done (early-packages-done)\n",
      "  HEUR episodes:\n",
      "    Ep01: reward= 4137.60, terminal_time=1216.00 min, rate= 3.403/min, accepted= 22, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward= 3554.22, terminal_time=1306.50 min, rate= 2.720/min, accepted= 18, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward= 1915.31, terminal_time= 887.50 min, rate= 2.158/min, accepted= 12, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward= 1478.55, terminal_time= 906.50 min, rate= 1.631/min, accepted=  9, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward= 2588.06, terminal_time=1076.00 min, rate= 2.405/min, accepted= 17, reason=packages_done (early-packages-done)\n",
      "  PURE episodes:\n",
      "    Ep01: reward=  338.00, terminal_time= 687.00 min, rate= 0.492/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep02: reward=  313.00, terminal_time= 613.50 min, rate= 0.510/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep03: reward=  323.00, terminal_time= 663.50 min, rate= 0.487/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep04: reward=  333.00, terminal_time= 692.50 min, rate= 0.481/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "    Ep05: reward=  335.00, terminal_time= 691.50 min, rate= 0.484/min, accepted=  0, reason=packages_done (early-packages-done)\n",
      "================================================================================\n",
      "Final evaluation over 5 eps (<= 1440 min each):\n",
      "  DRL (greedy):        R=3547.87, T=1206.00m, Rate=2.926/m, Acc=22.20\n",
      "  Nearby heuristic:    R=2734.75, T=1078.50m, Rate=2.463/m\n",
      "  Pure delivery only:  R=328.40, T=669.60m, Rate=0.491/m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
